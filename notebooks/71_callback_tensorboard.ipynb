{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "jupytext": {
      "split_at_heading": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "name": "71_callback.tensorboard.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "NzSj6Cg-8vuK",
        "iovild228vuM",
        "j4c27uNz8vuQ",
        "S6cA82Cn8vuS",
        "mScoYzfk8vuS",
        "wzSdhFyE8vuT",
        "h_KeaONz8vuU"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykato27/fastai/blob/main/71_callback_tensorboard.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoUTNLYp8vqV"
      },
      "source": [
        "#hide\n",
        "#skip\n",
        "! [ -e /content ] && pip install -Uqq fastai  # upgrade fastai on colab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51Rs1oab8vqf"
      },
      "source": [
        "#default_exp callback.tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzaJV-0C8vqg"
      },
      "source": [
        "#all_slow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFOiAuwa8vqi"
      },
      "source": [
        "#export\n",
        "from fastai.basics import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WAtg50-8vqj"
      },
      "source": [
        "# Tensorboard\n",
        "\n",
        "> Integration with [tensorboard](https://www.tensorflow.org/tensorboard) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cr1TLt8S8vqo"
      },
      "source": [
        "First thing first, you need to install tensorboard with\n",
        "```\n",
        "pip install tensorboard\n",
        "```\n",
        "Then launch tensorboard with\n",
        "``` \n",
        "tensorboard --logdir=runs\n",
        "```\n",
        "in your terminal. You can change the logdir as long as it matches the `log_dir` you pass to `TensorBoardCallback` (default is `runs` in the working directory)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNkeSV6L8vqp"
      },
      "source": [
        "## Tensorboard Embedding Projector support"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2O_e36t8vqq"
      },
      "source": [
        "> Tensorboard Embedding Projector is currently only supported for image classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wolfz9Yr8vqs"
      },
      "source": [
        "### Export Image Features during Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i699NYym8vqv"
      },
      "source": [
        "Tensorboard [Embedding Projector](https://www.tensorflow.org/tensorboard/tensorboard_projector_plugin) is supported in `TensorBoardCallback` (set parameter `projector=True`) during training. The validation set embeddings will be written after each epoch.\n",
        "\n",
        "```\n",
        "cbs = [TensorBoardCallback(projector=True)]\n",
        "learn = cnn_learner(dls, resnet18, metrics=accuracy)\n",
        "learn.fit_one_cycle(3, cbs=cbs)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McdKbo0B8vqx"
      },
      "source": [
        "### Export Image Features during Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-ecFLfN8vqy"
      },
      "source": [
        "To write the embeddings for a custom dataset (e. g. after loading a learner) use `TensorBoardProjectorCallback`. Add the callback manually to the learner.\n",
        "\n",
        "```\n",
        "learn = load_learner('path/to/export.pkl')\n",
        "learn.add_cb(TensorBoardProjectorCallback())\n",
        "dl = learn.dls.test_dl(files, with_labels=True)\n",
        "_ = learn.get_preds(dl=dl)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yOVFbfm8vqy"
      },
      "source": [
        "If using a custom model (non fastai-resnet) pass the layer where the embeddings should be extracted as a callback-parameter.\n",
        "\n",
        "```\n",
        "layer = learn.model[1][1]\n",
        "cbs = [TensorBoardProjectorCallback(layer=layer)]\n",
        "preds = learn.get_preds(dl=dl, cbs=cbs)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSaMYm4-8vqz"
      },
      "source": [
        "### Export Word Embeddings from Language Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KWHlc718vqz"
      },
      "source": [
        "To export word embeddings from Language Models (tested with AWD_LSTM (fast.ai) and GPT2 / BERT (transformers)) but works with every model that contains an embedding layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bcoAW5I8vq0"
      },
      "source": [
        "For a **fast.ai TextLearner or LMLearner** just pass the learner - the embedding layer and vocab will be extracted automatically:\n",
        "```\n",
        "dls = TextDataLoaders.from_folder(untar_data(URLs.IMDB), valid='test')\n",
        "learn = text_classifier_learner(dls, AWD_LSTM, drop_mult=0.5, metrics=accuracy)\n",
        "projector_word_embeddings(learn=learn, limit=2000, start=2000)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkOf5A0m8vq1"
      },
      "source": [
        "For other language models - like the ones in the **transformers library** - you'll have to pass the layer and vocab. Here's an example for a **BERT** model.\n",
        "```\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# get the word embedding layer\n",
        "layer = model.embeddings.word_embeddings\n",
        "\n",
        "# get and sort vocab\n",
        "vocab_dict = tokenizer.get_vocab()\n",
        "vocab = [k for k, v in sorted(vocab_dict.items(), key=lambda x: x[1])]\n",
        "\n",
        "# write the embeddings for tb projector\n",
        "projector_word_embeddings(layer=layer, vocab=vocab, limit=2000, start=2000)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yr-ztc5N8vq-"
      },
      "source": [
        "#export\n",
        "import tensorboard\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from fastai.callback.fp16 import ModelToHalf\n",
        "from fastai.callback.hook import hook_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMVBzvuD8vrA"
      },
      "source": [
        "#export\n",
        "class TensorBoardBaseCallback(Callback):\n",
        "    order = Recorder.order+1\n",
        "    \"Base class for tensorboard callbacks\"\n",
        "    def __init__(self): self.run_projector = False\n",
        "        \n",
        "    def after_pred(self):\n",
        "        if self.run_projector: self.feat = _add_projector_features(self.learn, self.h, self.feat)\n",
        "    \n",
        "    def after_validate(self):\n",
        "        if not self.run_projector: return\n",
        "        self.run_projector = False\n",
        "        self._remove()\n",
        "        _write_projector_embedding(self.learn, self.writer, self.feat)\n",
        "            \n",
        "    def after_fit(self): \n",
        "        if self.run: self.writer.close()\n",
        "        \n",
        "    def _setup_projector(self):\n",
        "        self.run_projector = True\n",
        "        self.h = hook_output(self.learn.model[1][1] if not self.layer else self.layer)\n",
        "        self.feat = {}\n",
        "        \n",
        "    def _setup_writer(self): self.writer = SummaryWriter(log_dir=self.log_dir)\n",
        "    def __del__(self): self._remove()\n",
        "    def _remove(self):\n",
        "        if getattr(self, 'h', None): self.h.remove()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGf_95ND8vrD"
      },
      "source": [
        "#export\n",
        "class TensorBoardCallback(TensorBoardBaseCallback):\n",
        "    \"Saves model topology, losses & metrics for tensorboard and tensorboard projector during training\"\n",
        "    def __init__(self, log_dir=None, trace_model=True, log_preds=True, n_preds=9, projector=False, layer=None):\n",
        "        super().__init__()\n",
        "        store_attr()\n",
        "\n",
        "    def before_fit(self):\n",
        "        self.run = not hasattr(self.learn, 'lr_finder') and not hasattr(self, \"gather_preds\") and rank_distrib()==0\n",
        "        if not self.run: return\n",
        "        self._setup_writer()\n",
        "        if self.trace_model:\n",
        "            if hasattr(self.learn, 'mixed_precision'):\n",
        "                raise Exception(\"Can't trace model in mixed precision, pass `trace_model=False` or don't use FP16.\")\n",
        "            b = self.dls.one_batch()\n",
        "            self.learn._split(b)\n",
        "            self.writer.add_graph(self.model, *self.xb)\n",
        "\n",
        "    def after_batch(self):\n",
        "        self.writer.add_scalar('train_loss', self.smooth_loss, self.train_iter)\n",
        "        for i,h in enumerate(self.opt.hypers):\n",
        "            for k,v in h.items(): self.writer.add_scalar(f'{k}_{i}', v, self.train_iter)\n",
        "\n",
        "    def after_epoch(self):\n",
        "        for n,v in zip(self.recorder.metric_names[2:-1], self.recorder.log[2:-1]):\n",
        "            self.writer.add_scalar(n, v, self.train_iter)\n",
        "        if self.log_preds:\n",
        "            b = self.dls.valid.one_batch()\n",
        "            self.learn.one_batch(0, b)\n",
        "            preds = getattr(self.loss_func, 'activation', noop)(self.pred)\n",
        "            out = getattr(self.loss_func, 'decodes', noop)(preds)\n",
        "            x,y,its,outs = self.dls.valid.show_results(b, out, show=False, max_n=self.n_preds)\n",
        "            tensorboard_log(x, y, its, outs, self.writer, self.train_iter)\n",
        "            \n",
        "    def before_validate(self):\n",
        "        if self.projector: self._setup_projector()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJMsMT3v8vt4"
      },
      "source": [
        "#export\n",
        "class TensorBoardProjectorCallback(TensorBoardBaseCallback):\n",
        "    \"Extracts and exports image featuers for tensorboard projector during inference\"\n",
        "    def __init__(self, log_dir=None, layer=None):\n",
        "        super().__init__()\n",
        "        store_attr()\n",
        "    \n",
        "    def before_fit(self):\n",
        "        self.run = not hasattr(self.learn, 'lr_finder') and hasattr(self, \"gather_preds\") and rank_distrib()==0\n",
        "        if not self.run: return\n",
        "        self._setup_writer()\n",
        "\n",
        "    def before_validate(self):\n",
        "        self._setup_projector()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaZxdt9f8vt5"
      },
      "source": [
        "#export\n",
        "def _write_projector_embedding(learn, writer, feat):\n",
        "    lbls = [learn.dl.vocab[l] for l in feat['lbl']] if getattr(learn.dl, 'vocab', None) else None     \n",
        "    vecs = feat['vec'].squeeze()\n",
        "    writer.add_embedding(vecs, metadata=lbls, label_img=feat['img'], global_step=learn.train_iter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzlzA9pN8vt6"
      },
      "source": [
        "#export\n",
        "def _add_projector_features(learn, hook, feat):\n",
        "    img = _normalize_for_projector(learn.x)\n",
        "    first_epoch = True if learn.iter == 0 else False\n",
        "    feat['vec'] = hook.stored if first_epoch else torch.cat((feat['vec'], hook.stored),0)\n",
        "    feat['img'] = img           if first_epoch else torch.cat((feat['img'], img),0)\n",
        "    if getattr(learn.dl, 'vocab', None):\n",
        "        feat['lbl'] = learn.y if first_epoch else torch.cat((feat['lbl'], learn.y),0)\n",
        "    return feat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNG2ShxV8vt6"
      },
      "source": [
        "#export\n",
        "def _get_embeddings(model, layer):\n",
        "    layer = model[0].encoder if layer == None else layer\n",
        "    return layer.weight"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bf0C1qQQ8vt8"
      },
      "source": [
        "#export\n",
        "@typedispatch\n",
        "def _normalize_for_projector(x:TensorImage):\n",
        "    # normalize tensor to be between 0-1\n",
        "    img = x.clone()\n",
        "    sz = img.shape\n",
        "    img = img.view(x.size(0), -1)\n",
        "    img -= img.min(1, keepdim=True)[0]\n",
        "    img /= img.max(1, keepdim=True)[0]\n",
        "    img = img.view(*sz)\n",
        "    return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSYPaA6L8vt9"
      },
      "source": [
        "# export\n",
        "from fastai.text.all import LMLearner, TextLearner"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4lG-YxB8vt9"
      },
      "source": [
        "#export\n",
        "def projector_word_embeddings(learn=None, layer=None, vocab=None, limit=-1, start=0, log_dir=None):\n",
        "    \"Extracts and exports word embeddings from language models embedding layers\"\n",
        "    if not layer:\n",
        "        if   isinstance(learn, LMLearner):   layer = learn.model[0].encoder\n",
        "        elif isinstance(learn, TextLearner): layer = learn.model[0].module.encoder\n",
        "    emb = layer.weight\n",
        "    img = torch.full((len(emb),3,8,8), 0.7)\n",
        "    vocab = learn.dls.vocab[0] if vocab == None else vocab\n",
        "    vocab = list(map(lambda x: f'{x}_', vocab))\n",
        "    writer = SummaryWriter(log_dir=log_dir)\n",
        "    end = start + limit if limit >= 0 else -1\n",
        "    writer.add_embedding(emb[start:end], metadata=vocab[start:end], label_img=img[start:end])\n",
        "    writer.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfrUfXrl8vt-"
      },
      "source": [
        "#export\n",
        "from fastai.vision.data import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eu12vkfy8vt_"
      },
      "source": [
        "#export\n",
        "@typedispatch\n",
        "def tensorboard_log(x:TensorImage, y: TensorCategory, samples, outs, writer, step):\n",
        "    fig,axs = get_grid(len(samples), add_vert=1, return_fig=True)\n",
        "    for i in range(2):\n",
        "        axs = [b.show(ctx=c) for b,c in zip(samples.itemgot(i),axs)]\n",
        "    axs = [r.show(ctx=c, color='green' if b==r else 'red')\n",
        "            for b,r,c in zip(samples.itemgot(1),outs.itemgot(0),axs)]\n",
        "    writer.add_figure('Sample results', fig, step)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyzI9jCf8vt_"
      },
      "source": [
        "#export\n",
        "from fastai.vision.core import TensorPoint,TensorBBox"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2jC4wm_8vuA"
      },
      "source": [
        "#export\n",
        "@typedispatch\n",
        "def tensorboard_log(x:TensorImage, y: (TensorImageBase, TensorPoint, TensorBBox), samples, outs, writer, step):\n",
        "    fig,axs = get_grid(len(samples), add_vert=1, return_fig=True, double=True)\n",
        "    for i in range(2):\n",
        "        axs[::2] = [b.show(ctx=c) for b,c in zip(samples.itemgot(i),axs[::2])]\n",
        "    for x in [samples,outs]:\n",
        "        axs[1::2] = [b.show(ctx=c) for b,c in zip(x.itemgot(0),axs[1::2])]\n",
        "    writer.add_figure('Sample results', fig, step)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-ecoLjZ8vuA"
      },
      "source": [
        "## TensorBoardCallback"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noLwUZk78vuA"
      },
      "source": [
        "from fastai.vision.all import Resize, RandomSubsetSplitter, aug_transforms, cnn_learner, resnet18"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3SrzRrU8vuB"
      },
      "source": [
        "path = untar_data(URLs.PETS)\n",
        "\n",
        "db = DataBlock(blocks=(ImageBlock, CategoryBlock), \n",
        "                  get_items=get_image_files, \n",
        "                  item_tfms=Resize(128),\n",
        "                  splitter=RandomSubsetSplitter(train_sz=0.1, valid_sz=0.01),\n",
        "                  batch_tfms=aug_transforms(size=64),\n",
        "                  get_y=using_attr(RegexLabeller(r'(.+)_\\d+.*$'), 'name'))\n",
        "\n",
        "dls = db.dataloaders(path/'images')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KT2IZEU_8vuB"
      },
      "source": [
        "learn = cnn_learner(dls, resnet18, metrics=accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNwqj8mw8vuB",
        "outputId": "9597d9dd-0fc1-4e97-d8e8-36748a4226ba"
      },
      "source": [
        "learn.unfreeze()\n",
        "learn.fit_one_cycle(3, cbs=TensorBoardCallback(Path.home()/'tmp'/'runs'/'tb', trace_model=True))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4.973294</td>\n",
              "      <td>5.009670</td>\n",
              "      <td>0.082192</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>4.382769</td>\n",
              "      <td>4.438282</td>\n",
              "      <td>0.095890</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>3.877172</td>\n",
              "      <td>3.665855</td>\n",
              "      <td>0.178082</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gKeH7cF8vuG"
      },
      "source": [
        "## Projector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzSj6Cg-8vuK"
      },
      "source": [
        "### Projector in TensorBoardCallback"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXSdyOD08vuK"
      },
      "source": [
        "path = untar_data(URLs.PETS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eDH461G8vuL"
      },
      "source": [
        "db = DataBlock(blocks=(ImageBlock, CategoryBlock), \n",
        "                  get_items=get_image_files, \n",
        "                  item_tfms=Resize(128),\n",
        "                  splitter=RandomSubsetSplitter(train_sz=0.05, valid_sz=0.01),\n",
        "                  batch_tfms=aug_transforms(size=64),\n",
        "                  get_y=using_attr(RegexLabeller(r'(.+)_\\d+.*$'), 'name'))\n",
        "\n",
        "dls = db.dataloaders(path/'images')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzTngv5q8vuL"
      },
      "source": [
        "cbs = [TensorBoardCallback(log_dir=Path.home()/'tmp'/'runs'/'vision1', projector=True)]\n",
        "learn = cnn_learner(dls, resnet18, metrics=accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEYecxJx8vuL",
        "outputId": "87ef6267-8584-44a9-8ad3-b290ef765dab"
      },
      "source": [
        "learn.unfreeze()\n",
        "learn.fit_one_cycle(3, cbs=cbs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>5.143322</td>\n",
              "      <td>6.736727</td>\n",
              "      <td>0.082192</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>4.508100</td>\n",
              "      <td>5.106580</td>\n",
              "      <td>0.109589</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>4.057889</td>\n",
              "      <td>4.194602</td>\n",
              "      <td>0.068493</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iovild228vuM"
      },
      "source": [
        "### TensorBoardProjectorCallback"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DdF58bJ8vuN"
      },
      "source": [
        "path = untar_data(URLs.PETS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6phigqOF8vuN"
      },
      "source": [
        "db = DataBlock(blocks=(ImageBlock, CategoryBlock), \n",
        "                  get_items=get_image_files, \n",
        "                  item_tfms=Resize(128),\n",
        "                  splitter=RandomSubsetSplitter(train_sz=0.1, valid_sz=0.01),\n",
        "                  batch_tfms=aug_transforms(size=64),\n",
        "                  get_y=using_attr(RegexLabeller(r'(.+)_\\d+.*$'), 'name'))\n",
        "\n",
        "dls = db.dataloaders(path/'images')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9OdehRi8vuO"
      },
      "source": [
        "files = get_image_files(path/'images')\n",
        "files = files[:256]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hBd4XWe8vuO"
      },
      "source": [
        "dl = learn.dls.test_dl(files, with_labels=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPII7rB88vuO"
      },
      "source": [
        "learn = cnn_learner(dls, resnet18, metrics=accuracy)\n",
        "layer = learn.model[1][0].ap\n",
        "cbs = [TensorBoardProjectorCallback(layer=layer, log_dir=Path.home()/'tmp'/'runs'/'vision2')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ip46VM_8vuP",
        "outputId": "7d065ece-832f-4756-9d0d-5ba7d39ba81c"
      },
      "source": [
        "_ = learn.get_preds(dl=dl, cbs=cbs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iC8DzSMu8vuP"
      },
      "source": [
        "## projector_word_embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4c27uNz8vuQ"
      },
      "source": [
        "### fastai text or lm learner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0F0UM1C8vuR"
      },
      "source": [
        "from fastai.text.all import TextDataLoaders, text_classifier_learner, AWD_LSTM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_D_pEsN8vuR"
      },
      "source": [
        "dls = TextDataLoaders.from_folder(untar_data(URLs.IMDB), valid='test')\n",
        "learn = text_classifier_learner(dls, AWD_LSTM, drop_mult=0.5, metrics=accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3MwzbFO8vuS"
      },
      "source": [
        "projector_word_embeddings(learn, limit=1000, log_dir=Path.home()/'tmp'/'runs'/'text')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6cA82Cn8vuS"
      },
      "source": [
        "### transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mScoYzfk8vuS"
      },
      "source": [
        "#### GPT2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9l7Dfzo28vuT"
      },
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n",
        "\n",
        "tokenizer = GPT2TokenizerFast.from_pretrained('gpt2')\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "layer = model.transformer.wte\n",
        "vocab_dict = tokenizer.get_vocab()\n",
        "vocab = [k for k, v in sorted(vocab_dict.items(), key=lambda x: x[1])]\n",
        "\n",
        "projector_word_embeddings(layer=layer, vocab=vocab, limit=2000, log_dir=Path.home()/'tmp'/'runs'/'transformers')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzSdhFyE8vuT"
      },
      "source": [
        "#### BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfRPeTo68vuT",
        "outputId": "8fe1478c-c440-4c2b-a4ec-ce6f40c94d96"
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "layer = model.embeddings.word_embeddings\n",
        "\n",
        "vocab_dict = tokenizer.get_vocab()\n",
        "vocab = [k for k, v in sorted(vocab_dict.items(), key=lambda x: x[1])]\n",
        "\n",
        "projector_word_embeddings(layer=layer, vocab=vocab, limit=2000, start=2000, log_dir=Path.home()/'tmp'/'runs'/'transformers')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "warning: Embedding dir exists, did you set global_step for add_embedding()?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_KeaONz8vuU"
      },
      "source": [
        "### Validate results in tensorboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAevqBMQ8vuU"
      },
      "source": [
        "Run the following command in the command line to check if the projector embeddings have been correctly wirtten:\n",
        "\n",
        "```\n",
        "tensorboard --logdir=~/tmp/runs\n",
        "```\n",
        "\n",
        "Open http://localhost:6006 in browser (TensorBoard Projector doesn't work correctly in Safari!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIcvEzYw8vuV"
      },
      "source": [
        "## Export -"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hyr9q7De8vuV"
      },
      "source": [
        "#hide\n",
        "from nbdev.export import *\n",
        "notebook2script()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a0ptIB78vv1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}